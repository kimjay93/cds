import streamlit as st
import pandas as pd
import numpy as np
import time
import util
import datetime as dt
from PIL import Image
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import joblib

def load_model():
    return joblib.load("lr.pkl")

def load_scaler():
    return joblib.load('scaler.pkl')

def load_pca():
    return joblib.load('pca.pkl')

def load_images():
    return {
        "pre_act_image" : Image.open('pre_act.png'),
        "pre_act_trend_image" : Image.open('pre_act_trend.png'),
        "shap_image" : Image.open('SHAP_fd.png')
    }
    
def analyzeDF():
    msg = st.toast('Reading...', icon="ğŸ“–")
    time.sleep(1)
    msg.toast('Analyzing...', icon="ğŸ§")
    time.sleep(2)
    msg.toast('Ready!', icon = "ğŸ””")
    
def convert_df(df_input):
    # VR Feed ê´€ë ¨ ì—´: [118:152]
    df_input_vr_feed = df_input.iloc[:, 118:152]
    
    # ì˜ë¯¸ì—†ëŠ” ë§¨ ì²« ì—´ ì œê±°í•˜ê³  ë‘ë²ˆì§¸ ì—´ì„ column ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
    df_input_vr_feed.columns = df_input_vr_feed.iloc[0]
    df_input_vr_feed = df_input_vr_feed[1:].reset_index(drop=True)
    
    # ì œê±°í•  ì—´: 0, 2, 5, 7,11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33
    col_to_drop = df_input_vr_feed.columns[[0, 2, 5, 7,11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33]]
    df_input_vr_feed.drop(col_to_drop, axis=1, inplace=True)
    df_input_vr_feed.drop('SEDEX', axis=1, inplace=True)
    # df dtype ë³€ê²½
    for col in df_input_vr_feed.columns:
        df_input_vr_feed[col] = df_input_vr_feed[col].astype('float64')
    
    # ê²°ì¸¡ì¹˜ëŠ” í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°
    for col in df_input_vr_feed.columns:
        df_input_vr_feed[col].fillna(df_input_vr_feed[col].mean(), inplace=True)
    
    # ìœ„ dfì— 2024ë…„ í‰ê·  ìš´ì „ ë°ì´í„°ë¥¼ merge
    # ë¨¼ì € 2024ë…„ í‰ê·  ìš´ì „ ë°ì´í„°ë¥¼ dfë¡œ êµ¬ì„±
    df = pd.read_csv('df_38thtrial.csv')
    df['Datetime'] = df['Datetime'].astype('datetime64[ns]')
    df.set_index('Datetime', drop=True, inplace=True)
    df = df.loc[df.index.year == 2024]
    opavg2024_list = []
    for col in df.columns[:15]:
        opavg2024_list.append(df[col].mean())
    opavg2024_df = pd.merge(pd.DataFrame(df.columns[:15]), pd.DataFrame(opavg2024_list), left_index=True, right_index=True)
    opavg2024_df.columns = ['variable', 'avg']
    opavg2024_df_t = opavg2024_df.transpose()
    opavg2024_df_t.columns = opavg2024_df_t.iloc[0]
    opavg2024_df_t = opavg2024_df_t[1:].reset_index(drop=True)
    opavg2024_df_t_repeated = pd.DataFrame([opavg2024_df_t.iloc[0]] * len(df_input_vr_feed), columns=opavg2024_df_t.columns)
    opavg2024_df_t_repeated.reset_index(drop=True, inplace=True)
    
    df = pd.concat([opavg2024_df_t_repeated, df_input_vr_feed], axis=1)
    return df
    # ì´í›„ scaler.pklì„ ì´ìš©í•œ í‘œì¤€í™”, Ni, Vì— ëŒ€í•œ pca ë° ni, v ì œê±°, vis100ì„ boxcoxë¡œ ë³€í™˜í•´ì•¼ SHFT ì˜ˆì¸¡ ê°€ëŠ¥í•¨
    return df
    # ì´í›„ scaler.pklì„ ì´ìš©í•œ standardization, pcaë¥¼ ì´ìš©í•œ Ni, V ê´€ë ¨ pca ì¶”ê°€ ë° ni, v ì œê±°ê¹Œì§€ í•´ì•¼ SHFT ì˜ˆì¸¡ ê°€ëŠ¥í•¨

def convert_df_info(df_input):
    # crude information ë‹´ê³  ìˆëŠ” df ë”°ë¡œ ì¶”ì¶œ
    df_info = df_input.iloc[:,4:6]
    df_info.columns = df_info.iloc[0]
    df_info = df_info[1:].reset_index(drop=True)
    return df_info
